# Database Configuration
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=vectordb
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_postgres_password

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_EMBEDDING_MODEL=text-embedding-3-large

# OpenAI Token Limits
MAX_TOKENS_PER_REQUEST=8050
MAX_TOKENS_PER_TEXT=7600

# Embedding Storage Configuration
EMBEDDING_BUFFER_SIZE=100
ENABLE_STREAMING_STORAGE=true

# Batch API Configuration
# Batch API avoids rate limits and provides 50% cost savings
# BUT has long wait times (5-60 minutes per file)
# Set to 'false' for immediate results with synchronous API
USE_BATCH_API=false

# Batch Pacing Configuration (prevents TPM bursts)
# Add delays between API call batches to stay under rate limits
DELAY_AFTER_BATCHES=5      # Add delay after every N batches
BATCH_DELAY_SECONDS=2      # Delay duration in seconds

# Engine Configuration (Optional)
DEFAULT_COLLECTION=documents
CHUNK_SIZE_LIMIT_MB=10
ENABLE_STREAMING=true
LOG_LEVEL=INFO

# Similarity Search Configuration
DEFAULT_SIMILARITY_THRESHOLD=0.3
SEARCH_RESULT_LIMIT=10
